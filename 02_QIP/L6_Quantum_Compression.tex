\documentclass[9pt]{beamer}
\usepackage{kotex}
\usepackage{amsfonts,amssymb,amsthm}
\usepackage[dvipsnames]{xcolor}
\usepackage{xcolor}
\usepackage{etoolbox}
\usepackage{braket}
\usepackage{qcircuit}

%## color
\definecolor{customBlack}{HTML}{3B4252}
\definecolor{customBlackGrey}{HTML}{434C5e}
\definecolor{cuatomGrey}{HTML}{4C566A} 
\definecolor{customWhite}{HTML}{ECEFF4} 
\definecolor{customBlue}{HTML}{6082B6}  
\definecolor{customRed}{HTML}{BF616A}
\definecolor{vividauburn}{rgb}{0.58, 0.15, 0.14}


%## Theme & custom
% \usetheme{metropolis}           % Use metropolis theme
% \metroset{block=fill}
\usetheme{moloch} % modern fork of the metropolis theme
\molochset{block=fill}
\setbeamersize{text margin left=5mm, text margin right=5mm}
\setbeamercolor{palette primary}{bg=customBlack}
\setbeamercolor{alerted text}{fg=customRed}
\setbeamercolor{itemize item}{fg=customBlue}
\setbeamercolor{enumerate item}{fg=customBlue}


%## font
\usefonttheme[onlymath]{serif}
% \setbeamerfont{normal text}{size=\small}
% \setbeamerfont{math text}{size=\tiny}


%## Theorem title, numbering
\makeatletter
\setbeamertemplate{theorem begin}
{%
\begin{\inserttheoremblockenv}
{%
\inserttheoremheadfont
\inserttheoremname
\ifx\inserttheoremaddition\@empty\else\ of\ \inserttheoremaddition\fi%
\inserttheorempunctuation
}%
}
\setbeamertemplate{theorem end}{\end{\inserttheoremblockenv}}
\makeatother
\setbeamertemplate{theorems}[numbered]  


%## Custom block
\setbeamercolor{block title}{bg=customBlue, fg=white}
\setbeamercolor{block body}{bg=customWhite, fg=customBlack}
\setbeamercolor{block title alerted}{%
    use={block title, alerted text},
    bg=customRed,
    fg=white
}
\setbeamercolor{block body alerted}{%
    use={block title, alerted text},
    bg=customWhite,
    fg=customBlack
}
\AtBeginEnvironment{definition}{%
    \setbeamercolor{block title}{fg=white,bg=customBlackGrey}
    \setbeamercolor{block body}{fg=customBlack, bg=customWhite}
}
\AtBeginEnvironment{theorem}{%
    \setbeamercolor{block title}{fg=white,bg=customBlackGrey}
    \setbeamercolor{block body}{fg=customBlack, bg=customWhite}
}
\AtBeginEnvironment{corollary}{%
    \setbeamercolor{block title}{fg=white,bg=customBlackGrey}
    \setbeamercolor{block body}{fg=customBlack, bg=customWhite}
}
\AtBeginEnvironment{lemma}{%
    \setbeamercolor{block title}{fg=white,bg=customBlackGrey}
    \setbeamercolor{block body}{fg=customBlack, bg=customWhite}
}


%! Useful command
\renewcommand{\Pr}{\text{Pr}}
% $\ast$ \underline{Proof}:
%\checkmark \underline{meaning}:

\title{6. Quantum compression}
\date{\today}
\author{Vaughan Sohn}
% \institute{Centre for Modern Beamer Themes}


\begin{document}
    %#################################### 
    \maketitle
    
    %#################################### 
    \begin{frame}
        \frametitle{Contents}
        \tableofcontents
    \end{frame}

    %#################################### 
    \begin{frame}
        \frametitle{Introduction}
        \begin{itemize}
            \item 동일한 arbitrary quantum state를 $n$개를 만드는(or 공유하는) 상황을 가정하자.
            \item \underline{Question}: Qubit $n$개로 표현할 수 있는 $\rho^{\otimes n}$ state를 구분하기 위해 과연 $n$개의 qubit을 모두 사용해야할까?
            \begin{equation*}
                \rho_i^{\otimes n} \ne {\rho}_j^{\otimes n}, \qquad \forall i,j,\ \ s.t.\ i \ne j
            \end{equation*}
            \item \underline{Answer}: $m = n \times S(\rho)$개의 qubit만 사용해도 구분할 수 있다!
            \item 이때, $S(\rho)$는 \textbf{폰 노이만 엔트로피}를 나타낸다. 
        \end{itemize}
        \vspace{0.4cm}
        이번 강의에서는 양자 상태의 정보의 양을 나타내기 위해 사용되는 척도인 폰 노이만 엔트로피에 대해서 소개하고, 폰 노이만 엔트로피가 어떻게 quantum compression과 연관되어있는지 설명하려고한다. 
    \end{frame}

    %#################################### 
    \begin{section}{Prerequirements: Entropy}
        \begin{frame}
            \frametitle{Classical entropy: Shannon entropy}
            \begin{definition}[Shannon entropy]
                Random variable $X$가 Probability distribution $P_X$를 따른다고 하자. ($X \sim P_X$) Shannon entropy는 다음과 같이 정의된다.
                \begin{equation*}
                    H(X) = - \sum_i P_X(i) \log P_X(i)
                \end{equation*}
            \end{definition}
            특히, 우리가 관심있는 \textit{bit}를 표현하는 binary r.v라면 다음과 같이 표현할 수 있다.
            \begin{equation*}
                H(X) = -P_X(0) \log P_X(0) - P_X(1) \log P_X(1)
            \end{equation*}
            \underline{Some remarks}:
            \begin{itemize}
                \item Shannon entropy는 어떤 random variable에 대한 정보량, 또는 모호성(ambiguity)을 나타내는 척도이다.
                \item Classical domain에서 Shannon entropy는 data compression, teleportation과 같은 다양한 작업에서 응용된다.
            \end{itemize}
        \end{frame}

        \begin{frame}
            \frametitle{Quantum entropy: von Neumann entropy}
            \begin{definition}[von Neumann entropy]
                Quantum state $\rho$에 대해 von Neumann entropy는 다음과 같이 정의된다.
                \begin{align}
                    S(\rho) &= - \text{tr}[\rho \log \rho] = -\sum_i \rho_{ii} \log \rho_{ii} \\
                            &= - \sum_i \lambda_i \log \lambda_i,
                \end{align}
                where $\rho = \sum_i q_i \rho(i)$ and $\{\lambda_i\} = \text{eig}(\rho)$.
            \end{definition}
            \vspace{0.2cm}
            \underline{Some remarks}:
            \begin{itemize}
                \item Eq.~(1)은 확률의 관점에서 폰 노이만 엔트로피를 해석한다.\footnote{density matrix의 대각성분은 확률을 의미하기 때문.}
                \item Eq.~(2)는 eigenvalue를 이용하여 폰 노이만 엔트로피를 해석한다.
            \end{itemize}
        \end{frame}
    \end{section}
    
    %#################################### 
    \begin{section}{Classical compression}
        \begin{frame}
            \frametitle{Typical sequence and Asymptotic Equipartition Property (AEP)}
            \begin{itemize}
                \item $n$ bit sequence를 가정하자. (i.i.d)
                \begin{equation*}
                    x^n_1 \triangleq x_1x_2 \cdots x_n \in \mathcal X^{n}, \qquad p(x^n_1) = p(x_1)p(x_2) \cdots p(x_n)
                \end{equation*}
                \item $n$ bit sequence의 empirical distribution은 다음과 같이 구할 수 있으며,\footnote{$n_0$: 0이 등장한 횟수, $n_1$: 1이 등장한 횟수. ($n_0 + n_1 = n$)} WLLN에 의해 empirical dist는 $n$이 커질수록 true dist와 가까워진다.
                \begin{equation*}
                    p(0) = \frac{n_0}{n}, \quad p(1) = \frac{n_1}{n}
                \end{equation*}
                \item 따라서 주어진 \textbf{$\mathbf n$ bit sequence의 확률}을 다음과 같이 표현할 수 있다.
                \begin{equation*}
                    p(x^n_1) \ \approx \ p(0)^{n_0}  p(1)^{n_1} = p(0)^{n p(0)}  p(1)^{n p(1)} 
                \end{equation*}
                \item 이는 다음과 같이 \alert{Shannon entropy}에 대한 term으로 표현할 수 있다.
                \begin{align*}
                    &\rightarrow \log p(x_q^n) = n\Big(p(0) \log p(0) + p(1) \log p(1)\Big) = -n H(X)\\
                    &\rightarrow p(x_q^n) = \boxed{2^{-n H(X)}}
                \end{align*}
                \item 즉, sequence가 어떤 bit값을 가지는지에 관계없이 \textit{empirical distribution과 true distribution}이 거의 유사하다면, Shannon entropy로 확률을 표현할 수 있다.
            \end{itemize}
        \end{frame}

        \begin{frame}
            \frametitle{Typical sequence and Asymptotic Equipartition Property (AEP)}
            앞의 아이디어를 이용하면, 다음의 정리를 정의할 수 있다.
            \begin{theorem}[Asymptotic Equipartition Property (AEP)]
                충분히 큰 $n$에 대해, \textbf{typical set}에 속하는 서로 다른 $n$-bit sequence의 확률은 거의 유사하다.
                \begin{equation*}
                    p(x_1^n) \ \approx \ p(\hat x_1^n) \ \approx \ 2^{-n H(X)}
                \end{equation*}
            \end{theorem}
            \begin{definition}[Typical set]
                다음과 같이 정의되는 set을 \textbf{typical set}이라고 부르며, typical set에 속하는 sequence를 typical sequence라고 한다. 
                \begin{equation*}
                    A_{\epsilon}^n = \Big\{x_1^n \ : \  2^{-n(H(X) + \epsilon)} \le p(x_1^n) \le 2^{-n (H(X) - \epsilon)}\Big\}
                \end{equation*}
            \end{definition}
            \begin{theorem}[Size of typical set]
                \vspace{-0.2cm}
                \begin{equation*}
                    |A_\epsilon^n| \le 2^{nH(X)}
                \end{equation*}
            \end{theorem}
            \textit{proof} : 확률의 정의에 의해 typical set안의 sequence에 대한 확률($=2^{-nH(X)}$)의 합과 typical set밖의 sequence의 확률의 합이 1이 되어야한다는 것을 이용.$\Box$
        \end{frame}

        \begin{frame}
            \frametitle{Classical compression}
            따라서 AEP를 이용하면, typical set안에 있는 sequence를 표현하기 위해 필요한 $m$ bit만 이용하여 $n$-bit sequence를 표현할 수 있다.\footnote{typical set의 크기, 확률로부터 typical set에 속하지 않는 원소의 확률은 0에 가깝다는 사실을 유추할 수 있다.}
            \begin{itemize}
                \item $m$ : minimal number of bits to describe $n$-bit sequence
                \item $n$ : length of original bit sequence
                \item $H(X)$ : \alert{compression rate}
                \begin{equation*}
                    m \cdot \underbrace{1}_{H}= n \cdot H(X),\quad \boxed{H(X) = \frac{m}{n}}
                \end{equation*}
                \item 만약 $X$가 완전한 random bit, 즉 uniform distribution을 따른다면, 엔트로피가 1이 되기 때문에 random bit는 압축할 수 없다. 
                \begin{equation*}
                    \text{if } X \sim P_U(X), \qquad \text{then } H(X) = \frac{1}{2} (- \log_2 \frac{1}{2} - \log_2 \frac{1}{2}) = 1
                \end{equation*}
                \item 따라서 classical compression은 $n$ biased bits를 압축하기 위해 $m$ random bits를 사용한다고 생각할 수 있다. ($n$ biased bits의 typical set의 크기와 $m$ random bits의 typical set의 크기가 비슷)
            \end{itemize}
        
        \end{frame}
    \end{section}

    %#################################### 
    \begin{section}{Quantum compression}
        \begin{frame}
            \frametitle{Quantum compression system}
            그렇다면, quantum compression에서도 quantum version의 entropy인 폰 노이만 엔트로피를 활용할 수 없을까?
            \begin{itemize}
                \item $n$ qubit system이 mixed state $\rho$에 대한 $n$개의 복사본 $\rho^{\otimes n}$으로 준비되어있다.
                \begin{equation*}
                    \rho = \sum_i p(i) \ket{\psi_i} \bra{\psi_i}
                \end{equation*}
                \item 이때, $\rho$는 다음과 같이 eigenvalue와 eigenvector로 나타낼 수 있다. $\rho$의 eigenvector는 2개이며\footnote{$\rho$는 single qubit이므로} eigenvalue는 \textit{probability condition}을 만족하며,
                \begin{equation*}
                    \rho = \sum_i\lambda_i\ket{u_i} \bra{u_i} = \lambda_0\ket{u_0} \bra{u_0} + \lambda_1\ket{u_1} \bra{u_1}
                \end{equation*}
                \item 위의 표현을 이용하면, $n$ qubit system을 다음과 같이 표현할 수 있다.
                \begin{align*}
                    \rho^{\otimes n}&=  \sum_{i_1}\lambda_{i_1}\ket{u_{i_1}}\bra{u_{i_1}} \otimes  \sum_{i_2}\lambda_{i_2}\ket{u_{i_2}} \bra{u_{i_2}} \otimes \cdots \otimes  \sum_{i_n}\lambda_i\ket{u_{i_n}} \bra{u_{i_n}}\\ 
                                    &= \sum_{i_1, \cdots, i_n} \lambda_{i_1} \lambda_{i_2} \cdots \lambda_{i_n} \ket{u_{i_1} u_{i_2} \cdots u_{i_n}}\bra{u_{i_1} u_{i_2} \cdots u_{i_n}}
                \end{align*}
            \end{itemize}
        \end{frame}

        \begin{frame}
            \frametitle{Quantum compression system}
            \begin{itemize}
                \item (아이디어) 이때, $\lambda$의 index를 나타내는 $i_1, i_2, \cdots i_n$을 $n$-bit string으로 생각할 수 있다. ($i_j \in \{0, 1\}$) 따라서 이를 $X \sim P_X$로 나타내면,
                \begin{equation*}
                    \rho^{\otimes n} = \sum_{x_1, \cdots, x_n} \lambda_{x_1} \lambda_{x_2} \cdots \lambda_{x_n} \ket{u_{x_1} u_{x_2} \cdots u_{x_n}}\bra{u_{x_1} u_{x_2} \cdots u_{x_n}}.
                \end{equation*}
                \item 따라서 WLLN에 의해, 이 상태는 typical set안에 들어있는 $x_1^n$만 사용하여 표현할 수 있고, 따라서 entropy를 이용하여 표현하면, 다음과 같다.
                \begin{align*}
                    \rho^{\otimes n}    &= \sum_{x_1^n \in A^{n}_\epsilon} \underbrace{\lambda_{x_1} \lambda_{x_2} \cdots \lambda_{x_n}}_{\approx 2^{-n S(\rho)}} \ket{u_{x_1} u_{x_2} \cdots u_{x_n}}\bra{u_{x_1} u_{x_2} \cdots u_{x_n}} \\
                                        &+  \sum_{x_1^n \notin A^{n}_\epsilon} \underbrace{\lambda_{x_1} \lambda_{x_2} \cdots \lambda_{x_n}}_{\approx 0} \ket{u_{x_1} u_{x_2} \cdots u_{x_n}}\bra{u_{x_1} u_{x_2} \cdots u_{x_n}}  \\
                                        &\approx 2^{-n S(\rho)}  \sum_{x_1^n \in A^{n}_\epsilon}  \ket{u_{x_1} u_{x_2} \cdots u_{x_n}}\bra{u_{x_1} u_{x_2} \cdots u_{x_n}}
                \end{align*}
                \item 이때, 다음은 \textbf{typical subspace}에 투영시키는 projector로 이해할 수 있다.
                \begin{equation*}
                    P_\epsilon^n \triangleq \sum_{x_1^n \in A^{n}_\epsilon}  \ket{u_{x_1} u_{x_2} \cdots u_{x_n}}\bra{u_{x_1} u_{x_2} \cdots u_{x_n}}
                \end{equation*}
                typical subspace는 다음과 같다.
                $ \mathcal H = \text{span} \Big\{ \ket{u_{x_1}u_{x_2} \cdots u_{x_n}} \ : \ x_1^n \in A_\epsilon^n \Big\} $
            \end{itemize}
        \end{frame}

        \begin{frame}
            \frametitle{Quantum compression system}
            \begin{itemize}
                \item 앞에서 정의한 projector $P_\epsilon^n$을 $n$ qubit state에 가했을 때, trace는 다음과 같다.
                \begin{equation*}
                    \text{tr}[\rho^{\otimes n}P_\epsilon^n]  = \sum_{ x_1^n \in A_\epsilon^n} \lambda_{x_1} \cdots \lambda_{x_n} = |A_{\epsilon}^n| \cdot 2^{-nS(\rho)} \approx 1.
                \end{equation*}    
                이는 typical subspace에 $\rho^{\otimes n}$가 존재할 확률로 해석할 수 있으며, 따라서 \textbf{대부분의 quantum state가 typical subspace에 존재한다}는 것을 알 수 있다.
                \item 따라서 $n$ qubit state를 projector를 사용하여 typical subspace로 투영하면, typical subspace의 dimension에 해당하는 수의 qubit만 사용하여 state를 나타낼 수 있다.
                \begin{equation*}
                    P_{\epsilon}^n \rho^{\otimes n} P_\epsilon^n \approx \rho^{\otimes n}
                \end{equation*}
                typical subspace의 차원은 $2^{nS(\rho)}$이므로, $\color{red} n S(\rho)$개의 qubit만 있으면 표현가능하다!
                \begin{equation*}
                    m \cdot 1 = n \cdot S(\rho), \quad \boxed{R = S(\rho) = \frac{m}{n}}
                \end{equation*}
                \item 반면, $\rho$가 완전히 랜덤이라면 classical case와 마찬가지로 더 이상 압축할 수 없다.
                \begin{equation*}
                    \text{if } \sigma = \frac{1}{2} \ket{0}\bra{0} + \ket{1} \bra{1}, \text{ then } R = 1.
                \end{equation*}
            \end{itemize}
        \end{frame}

        \begin{frame}
            \frametitle{Some remarks of von Neumann entropy}
            \underline{Question}: 두 개의 $n$-qubit state 중에서 어떤 state가 더 많은 information을 가지는가?
            \begin{itemize}
                \item 각 state의 엔트로피를 비교하자. (또는 $m$)
                \begin{equation*}
                    S(\rho_1) =\frac{m_1}{n},\quad  S(\rho_2) \frac{m_2}{2}
                \end{equation*}
                \item 두 state중에서 엔트로피가 더 큰 state가 더 random한 상태에 가까워지며, 따라서 더 많은 information; uncertainty를 가진다.
            \end{itemize}
            \vspace{0.4cm}
            \underline{Question}: (폰 노이만) 엔트로피의 최댓값과 최솟값은?
            \begin{itemize}
                \item $S(\rho) = 0$는 mixed state에 대해 uncertainty가 없다는 의미이므로 \alert{pure state}이다.
                \item $S(\rho) = 1$는 각 pure state의 확률이 $1/2$인 \alert{maximally mixed state}이다.
                \begin{equation*}
                    0 \le S(\rho) \le 1
                \end{equation*}
            \end{itemize}
            \vspace{0.4cm}
            \underline{Question}: 두 개의 $n$-qubit state중에서 어떤 state가 더 가치있을까?
            \begin{itemize}
                \item Quantum compression을 이용하면 두 state는 각각 폰 노이만 엔트로피에 따라 \alert{maximally mixed qubit} $m_1, m_2$개로 표현된다.
                \item 물건의 가치를 화폐로 정의하는 것처럼, qubit의 가치는 몇 개의 maximally mixed qubit이 필요했는가로 정의된다.
            \end{itemize}
        \end{frame}
    \end{section}

    %#################################### 
    \begin{frame}{Summary}
        \begin{block}{Summary}
            \begin{itemize}
                \item Entropy: information; uncertainty를 나타내는 measure 
                \begin{itemize}
                    \item Shannon entropy: 
                    \begin{equation*}
                        H(X) = - \sum_i P_X(i) \log P_X(i)
                    \end{equation*}
                    \item von Neumann entropy: 
                    \begin{equation*}
                        S(\rho) = \text{tr} [\rho \log \rho] = -\sum_i \lambda_i \log \lambda_i
                    \end{equation*}
                \end{itemize}
                \item Typical sequence and Asymptotic Equipartition Property (AEP)
                \begin{itemize}
                    \item Typical set: empirical distribution과 true distribution이 거의 유사한 sequence들의 집합 
                        $A_{\epsilon}^n = \Big\{x_1^n \ : \  2^{-n(H(X) + \epsilon)} \le p(x_1^n) \le 2^{-n (H(X) - \epsilon)}\Big\}$
                    \item Typical subspace: typical set에 해당하는 sequence를 인덱스로 갖는 quantum state들이 span하는 공간 $
                        \mathcal H = \text{span} \Big\{ \ket{u_{x_1}u_{x_2} \cdots u_{x_n}} \ : \ x_1^n \in A_\epsilon^n \Big\}$
                    \item AEP: typical set에 속하는 sequence들의 확률은 $2^{-nH(X)}$이다.
                    \item (Quantum) AEP: typical subspace에 속하는 quantum state의 확률은 $2^{-nS(\rho)}$이다.
                \end{itemize}
            \item Compression rate
            \begin{itemize}
                \item Classical case: $R = H(X)$
                \item Quantum case: $R = S(\rho)$
            \end{itemize}
            \end{itemize}
        \end{block}
    \end{frame}


    %#################################### 
    \begin{frame}{References}
        \begin{itemize}
            \item Lecture notes for EE547: Introduction to Quantum Information Processing (Fall 2024)
        \end{itemize}
        \vspace{6cm}
    \end{frame}


\end{document}